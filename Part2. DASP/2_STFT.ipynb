{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STFT(Short Time Fourier Transform)**\n",
    "\n",
    "- 신호를 일정길이의 구간으로 나눠 구간별로 FFT하는 방법입니다.\n",
    "\n",
    "위에서 언급했듯 전체 시간에 대해 푸리에 변환을 하는 DFT에서는 특정 시간에 어떤 주파수 성분이 들어있는지 알 수 없다. 이러한 문제를 해결하기 위해 아주 짧은 시간에서는 특성이 고정되어있다고 가정을 하고 신호를 짧은 구간으로 나눠 각각 FFT한다.  \n",
    "\n",
    "**Framing, Windowing**\n",
    "\n",
    "**Framing**은 음성데이터를 짧게 분할하는 과정입니다.\n",
    "\n",
    "음성 신호는 고정되어 있지 않습니다.(non -stationary) 예를 들어 같은 단어를 말한다해도 사람마다 그 길이는 다릅니다. 그렇기 때문에 음성이 변하지 않는 수준의 최소 음소단위로 짧게 분할하는 과정을 거쳐야합니다. 일반적으로 음성 Domain에서는 발성하는 음소가 바뀔수 없는 단위인 20~30ms으로 구간을 설정하고,  50%정도의 구간을 겹치게(overlap) 분할합니다.\n",
    "\n",
    "**Windowing**은 분할된 Frame의 경계를 부드럽게 연결되도록 만드는 과정입니다.\n",
    "\n",
    "각 분할된 Frame은 연속적으로 이어지지 않습니다. 연속적이지 않은 접합되는 부분의 기울기가 무한대로 되는 문제가 발생합니다. 이를 해결하기 위해 window를 적용해서 각 Frame의 시작과 끝을 이어주는 과정을 거치게 됩니다. 일반적으로 Hamming Window를 사용합니다.\n",
    "\n",
    "window 크기를 작게 할 수록 시간축을 잘게 나눈다는 뜻이니 time resolution이 증가하고 반대로 window 크기를 키우면 frequency resolution이 증가합니다.\n",
    "\n",
    "![Untitled](DSP_1/stft_.png)\n",
    "\n",
    "### 파이썬 구현\n",
    "\n",
    "librosa 라이브러리를 통해 구현할 수 있습니다. stft함수의 파라미터는 다음과 같습니다.\n",
    "\n",
    "x: audio 신호\n",
    "\n",
    "n_fft: 주파수 샘플 개수\n",
    "\n",
    "hop_length: 얼마나 shift 해주는지\n",
    "\n",
    "win_length: window 길이\n",
    "\n",
    "window: window 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stft\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa \n",
    "\n",
    "def sin_wave(amp, freq, time):\n",
    "    return amp*np.sin(2*np.pi*freq*time)\n",
    "\n",
    "time = np.arange(0, 10, 0.01)                       ## 1초까지 시간을 0.01초 간격으로 샘플링\n",
    "\n",
    "sin1 = sin_wave(amp= 2, freq= 1, time= time)       ## 서로 다른 진폭과 주파수를 가지는 간단한 사인파\n",
    "sin2 = sin_wave(4, 10, time)\n",
    "sin3 = sin_wave(8, 20, time)\n",
    "\n",
    "complex_wav1 = sin1 + sin2 + sin3   \n",
    "\n",
    "time1 = np.arange(0, 3.3, 0.01)    \n",
    "time2 = np.arange(3.3, 6.6, 0.01) \n",
    "time3 = np.arange(6.6, 9.99, 0.01) \n",
    "\n",
    "sin1 = sin_wave(2, 1, time1)       \n",
    "sin2 = sin_wave(4, 10, time2)\n",
    "sin3 = sin_wave(8, 20, time3)\n",
    "\n",
    "complex_wav2 = np.concatenate((sin1, sin2, sin3)) \n",
    "\n",
    "y1 = librosa.stft(complex_wav1, n_fft=128, hop_length=64, win_length=128)\n",
    "y2 = librosa.stft(complex_wav2, n_fft=128, hop_length=64, win_length=128)\n",
    "\n",
    "magnitude1 = np.abs(y1)\n",
    "magnitude2 = np.abs(y2)\n",
    "log_spectrogram1 = librosa.amplitude_to_db(magnitude1)\n",
    "log_spectrogram2 = librosa.amplitude_to_db(magnitude2)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize = (16,8))\n",
    "img = librosa.display.specshow(log_spectrogram1, hop_length=64, x_axis = 'time', ax = ax[0])\n",
    "ax[0].set(title='Spectrogram1 (dB)')\n",
    "librosa.display.specshow(log_spectrogram2, hop_length=64, x_axis = 'time', ax = ax[1])\n",
    "ax[1].set(title='Spectrogram2 (dB)')\n",
    "fig.colorbar(img,format='%+2.0f dB',ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Untitled](DSP_1/stft.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10651024f7bb74ad8b3a7880b38bbb6e915f32f23f7415cc617a62eadb9eb91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
